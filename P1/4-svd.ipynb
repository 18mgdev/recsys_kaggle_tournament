{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miembros del grupo \"Los hiperpar√°metros\" üôç‚Äç‚ôÇÔ∏èüôç‚Äç‚ôÄÔ∏èüôç‚Äç‚ôÇÔ∏è\n",
    "\n",
    "- MIGUEL GONZ√ÅLEZ GARC√çA\n",
    "- ROSA L√ìPEZ ESCALONA\n",
    "- JAVIER QUESADA PAJARES\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJEMPLO DE LOS GRIDSEARCH QUE HEMOS HECHO. EN ESTE CASO SVD (Public Score: 1.244)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports üîß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento del dataset üßπ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Datos cargados: 390351 registros de entrenamiento, 43320 registros de prueba.\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando datos...\")\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "print(f\"Datos cargados: {len(train_data)} registros de entrenamiento, {len(test_data)} registros de prueba.\")\n",
    "\n",
    "# Formato de Surprise\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(train_data[['user', 'item', 'rating']], reader)\n",
    "\n",
    "# Divisi√≥n en conjunto de entrenamiento y validaci√≥n\n",
    "trainset, valset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calcular medias de usuario y de √≠tem\n",
    "user_means = train_data.groupby('user')['rating'].mean().to_dict()\n",
    "item_means = train_data.groupby('item')['rating'].mean().to_dict()\n",
    "global_mean = train_data['rating'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento GridSearch SVD üèãÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando GridSearch...\n",
      "Mejor combinaci√≥n de hiperpar√°metros: {'n_factors': 20, 'n_epochs': 50, 'biased': True, 'lr_all': 0.002, 'reg_all': 0.02}\n",
      "Entrenando el mejor modelo SVD...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x18392519990>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rango de hiperpar√°metros para GridSearch\n",
    "param_grid = {\n",
    "    'n_factors': [20, 50, 100],\n",
    "    'n_epochs': [20, 50],\n",
    "    'biased': [True],\n",
    "    'lr_all': [0.002, 0.005],\n",
    "    'reg_all': [0.02, 0.05]\n",
    "}\n",
    "\n",
    "print(\"Iniciando GridSearch...\")\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['mae'], cv=3, n_jobs=-1)\n",
    "grid_search.fit(data)\n",
    "\n",
    "# Mejor combinaci√≥n\n",
    "best_params = grid_search.best_params['mae']\n",
    "print(f\"Mejor combinaci√≥n de hiperpar√°metros: {best_params}\")\n",
    "\n",
    "# Crea el modelo SVD con los mejores hiperpar√°metros\n",
    "best_svd = SVD(**best_params)\n",
    "print(\"Entrenando el mejor modelo SVD...\")\n",
    "best_svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones y generaci√≥n de CSV üß†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(uid, iid):\n",
    "    try:\n",
    "        # Predicci√≥n usando el mejor modelo SVD\n",
    "        pred = best_svd.predict(uid, iid).est\n",
    "    except:\n",
    "        pred = None\n",
    "\n",
    "    # Si la predicci√≥n no es v√°lida, utilizar medias\n",
    "    if pred is None or np.isnan(pred) or pred == 0:\n",
    "        if uid in user_means and iid in item_means:\n",
    "            pred = (user_means[uid] + item_means[iid]) / 2\n",
    "        elif uid in user_means:\n",
    "            pred = user_means[uid]\n",
    "        elif iid in item_means:\n",
    "            pred = item_means[iid]\n",
    "        else:\n",
    "            pred = global_mean\n",
    "\n",
    "    return f\"{round(max(1, min(10, pred)))}.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando predicciones para el conjunto de prueba...\n",
      "Guardando archivo de predicciones...\n",
      "Archivo 'predictions_svd_gridsearch.csv' generado correctamente.\n"
     ]
    }
   ],
   "source": [
    "print(\"Generando predicciones para el conjunto de prueba...\")\n",
    "predictions = []\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    uid, iid, row_id = row['user'], row['item'], row['ID']\n",
    "    pred_rating = predict_rating(uid, iid)\n",
    "    predictions.append((row_id, pred_rating))\n",
    "\n",
    "print(\"Guardando archivo de predicciones...\")\n",
    "predictions_df = pd.DataFrame(predictions, columns=[\"ID\", \"rating\"])\n",
    "predictions_df.to_csv(\"predictions_svd_gridsearch.csv\", index=False)\n",
    "print(\"Archivo 'predictions_svd_gridsearch.csv' generado correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
