{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1: Carga de Librerías y Datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media global de ratings: 7.6047\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\", sep=\",\")\n",
    "test_data = pd.read_csv(\"data/test.csv\", sep=\",\")\n",
    "\n",
    "global_mean = train_data['rating'].mean()\n",
    "print(f\"Media global de ratings: {global_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25715</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25716</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>25851</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>25923</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>25924</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user   item  rating\n",
       "0     1  25715     7.0\n",
       "1     1  25716    10.0\n",
       "2     5  25851     9.0\n",
       "3     6  25923     5.0\n",
       "4     7  25924     6.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8117</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10512</td>\n",
       "      <td>24393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>534</td>\n",
       "      <td>1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10984</td>\n",
       "      <td>6550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9093</td>\n",
       "      <td>22128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   user   item\n",
       "0   0   8117    268\n",
       "1   1  10512  24393\n",
       "2   2    534   1334\n",
       "3   3  10984   6550\n",
       "4   4   9093  22128"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data, val_split = train_test_split(train_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de usuarios: 73456\n",
      "Número de ítems: 171171\n"
     ]
    }
   ],
   "source": [
    "# Obtener listas únicas de usuarios e ítems del conjunto de entrenamiento\n",
    "unique_users = train_data['user'].unique()\n",
    "unique_items = train_data['item'].unique()\n",
    "\n",
    "# Crear índices para usuarios e ítems\n",
    "user_to_index = {user: idx for idx, user in enumerate(unique_users)}\n",
    "item_to_index = {item: idx for idx, item in enumerate(unique_items)}\n",
    "\n",
    "# Dimensiones de la matriz de ratings\n",
    "num_users = len(unique_users)\n",
    "num_items = len(unique_items)\n",
    "\n",
    "print(f\"Número de usuarios: {num_users}\")\n",
    "print(f\"Número de ítems: {num_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz dispersa creada con dimensiones: (73456, 171171)\n",
      "Número de ratings no nulos en la matriz: 390351\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Crear la matriz dispersa solo con el conjunto de entrenamiento\n",
    "rows = train_data['user'].map(user_to_index).values\n",
    "cols = train_data['item'].map(item_to_index).values\n",
    "ratings = train_data['rating'].values\n",
    "\n",
    "R_sparse = csr_matrix((ratings, (rows, cols)), shape=(num_users, num_items))\n",
    "\n",
    "print(f\"Matriz dispersa creada con dimensiones: {R_sparse.shape}\")\n",
    "print(\"Número de ratings no nulos en la matriz:\", R_sparse.nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factores latentes inicializados: U ((73456, 15)), V ((171171, 15))\n",
      "Sesgos inicializados: bu ((73456,)), bi ((171171,))\n"
     ]
    }
   ],
   "source": [
    "# Celda 3: Inicialización de Parámetros y Factores Latentes con Bias\n",
    "# Hiperparámetros\n",
    "k = 15  # Número de factores latentes\n",
    "lambda_ = 0.02  # Regularización\n",
    "learning_rate = 0.002  # Tasa de aprendizaje\n",
    "num_epochs = 80  # Número de iteraciones\n",
    "\n",
    "# Media global de ratings\n",
    "mu = global_mean\n",
    "\n",
    "# Inicialización aleatoria de las matrices latentes U y V\n",
    "U = np.random.normal(scale=1./k, size=(num_users, k))\n",
    "V = np.random.normal(scale=1./k, size=(num_items, k))\n",
    "\n",
    "# Inicialización de sesgos\n",
    "bu = np.zeros(num_users)\n",
    "bi = np.zeros(num_items)\n",
    "\n",
    "print(f\"Factores latentes inicializados: U ({U.shape}), V ({V.shape})\")\n",
    "print(f\"Sesgos inicializados: bu ({bu.shape}), bi ({bi.shape})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4: Función de Entrenamiento PMF con Bias\n",
    "def train_pmf_with_bias(R_sparse, U, V, bu, bi, mu, lambda_, lr, num_epochs):\n",
    "    rows, cols = R_sparse.nonzero()\n",
    "    num_ratings = len(rows)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_cost = 0\n",
    "        for idx in range(num_ratings):\n",
    "            i = rows[idx]  # Usuario\n",
    "            j = cols[idx]  # Ítem\n",
    "            r_ij = R_sparse[i, j]\n",
    "\n",
    "            # Predicción incluyendo el sesgo\n",
    "            pred_ij = mu + bu[i] + bi[j] + np.dot(U[i, :], V[j, :])\n",
    "            error = r_ij - pred_ij\n",
    "\n",
    "            # Actualización de los factores latentes y sesgos\n",
    "            bu[i] += lr * (error - lambda_ * bu[i])\n",
    "            bi[j] += lr * (error - lambda_ * bi[j])\n",
    "            U[i, :] += lr * (error * V[j, :] - lambda_ * U[i, :])\n",
    "            V[j, :] += lr * (error * U[i, :] - lambda_ * V[j, :])\n",
    "\n",
    "            # Costo regularizado\n",
    "            total_cost += error**2 + (lambda_ / 2) * (np.linalg.norm(U[i, :])**2 + np.linalg.norm(V[j, :])**2 + bu[i]**2 + bi[j]**2)\n",
    "\n",
    "        print(f\"Época {epoch + 1}/{num_epochs} - Costo total: {total_cost:.4f}\")\n",
    "\n",
    "    return U, V, bu, bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento PMF...\n",
      "Época 1/80 - Costo total: 1261260.1712\n",
      "Época 2/80 - Costo total: 1194640.8949\n",
      "Época 3/80 - Costo total: 1156729.4223\n",
      "Época 4/80 - Costo total: 1128957.6697\n",
      "Época 5/80 - Costo total: 1106614.3543\n",
      "Época 6/80 - Costo total: 1087707.0918\n",
      "Época 7/80 - Costo total: 1071185.7238\n",
      "Época 8/80 - Costo total: 1056421.8533\n",
      "Época 9/80 - Costo total: 1043007.3494\n",
      "Época 10/80 - Costo total: 1030660.6685\n",
      "Época 11/80 - Costo total: 1019177.7094\n",
      "Época 12/80 - Costo total: 1008403.7290\n",
      "Época 13/80 - Costo total: 998216.1533\n",
      "Época 14/80 - Costo total: 988513.4003\n",
      "Época 15/80 - Costo total: 979207.2263\n",
      "Época 16/80 - Costo total: 970217.3542\n",
      "Época 17/80 - Costo total: 961467.9164\n",
      "Época 18/80 - Costo total: 952885.8616\n",
      "Época 19/80 - Costo total: 944401.9880\n",
      "Época 20/80 - Costo total: 935955.5476\n",
      "Época 21/80 - Costo total: 927502.9302\n",
      "Época 22/80 - Costo total: 919029.1030\n",
      "Época 23/80 - Costo total: 910557.1326\n",
      "Época 24/80 - Costo total: 902148.1546\n",
      "Época 25/80 - Costo total: 893885.9136\n",
      "Época 26/80 - Costo total: 885849.0666\n",
      "Época 27/80 - Costo total: 878085.0163\n",
      "Época 28/80 - Costo total: 870599.4943\n",
      "Época 29/80 - Costo total: 863364.2734\n",
      "Época 30/80 - Costo total: 856333.6361\n",
      "Época 31/80 - Costo total: 849459.0377\n",
      "Época 32/80 - Costo total: 842697.5348\n",
      "Época 33/80 - Costo total: 836014.8385\n",
      "Época 34/80 - Costo total: 829385.4139\n",
      "Época 35/80 - Costo total: 822791.4412\n",
      "Época 36/80 - Costo total: 816221.5196\n",
      "Época 37/80 - Costo total: 809669.3989\n",
      "Época 38/80 - Costo total: 803132.7635\n",
      "Época 39/80 - Costo total: 796612.0376\n",
      "Época 40/80 - Costo total: 790109.2121\n",
      "Época 41/80 - Costo total: 783626.7503\n",
      "Época 42/80 - Costo total: 777166.6684\n",
      "Época 43/80 - Costo total: 770729.8863\n",
      "Época 44/80 - Costo total: 764315.9048\n",
      "Época 45/80 - Costo total: 757922.8029\n",
      "Época 46/80 - Costo total: 751547.4892\n",
      "Época 47/80 - Costo total: 745186.1083\n",
      "Época 48/80 - Costo total: 738834.4984\n",
      "Época 49/80 - Costo total: 732488.6148\n",
      "Época 50/80 - Costo total: 726144.8684\n",
      "Época 51/80 - Costo total: 719800.3562\n",
      "Época 52/80 - Costo total: 713452.9843\n",
      "Época 53/80 - Costo total: 707101.4999\n",
      "Época 54/80 - Costo total: 700745.4518\n",
      "Época 55/80 - Costo total: 694385.1042\n",
      "Época 56/80 - Costo total: 688021.3228\n",
      "Época 57/80 - Costo total: 681655.4513\n",
      "Época 58/80 - Costo total: 675289.1904\n",
      "Época 59/80 - Costo total: 668924.4886\n",
      "Época 60/80 - Costo total: 662563.4483\n",
      "Época 61/80 - Costo total: 656208.2517\n",
      "Época 62/80 - Costo total: 649861.1032\n",
      "Época 63/80 - Costo total: 643524.1896\n",
      "Época 64/80 - Costo total: 637199.6544\n",
      "Época 65/80 - Costo total: 630889.5838\n",
      "Época 66/80 - Costo total: 624596.0012\n",
      "Época 67/80 - Costo total: 618320.8687\n",
      "Época 68/80 - Costo total: 612066.0918\n",
      "Época 69/80 - Costo total: 605833.5264\n",
      "Época 70/80 - Costo total: 599624.9859\n",
      "Época 71/80 - Costo total: 593442.2474\n",
      "Época 72/80 - Costo total: 587287.0561\n",
      "Época 73/80 - Costo total: 581161.1276\n",
      "Época 74/80 - Costo total: 575066.1477\n",
      "Época 75/80 - Costo total: 569003.7701\n",
      "Época 76/80 - Costo total: 562975.6121\n",
      "Época 77/80 - Costo total: 556983.2493\n",
      "Época 78/80 - Costo total: 551028.2083\n",
      "Época 79/80 - Costo total: 545111.9602\n",
      "Época 80/80 - Costo total: 539235.9135\n",
      "Entrenamiento completado.\n"
     ]
    }
   ],
   "source": [
    "# Celda 5: Entrenamiento del Modelo PMF\n",
    "print(\"Iniciando entrenamiento PMF...\")\n",
    "U, V, bu, bi = train_pmf_with_bias(R_sparse, U, V, bu, bi, mu, lambda_, learning_rate, num_epochs)\n",
    "print(\"Entrenamiento completado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_for_xgboost(R_sparse, U, V):\n",
    "    rows, cols = R_sparse.nonzero()\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i, j in zip(rows, cols):\n",
    "        u_vec = U[i]  # vector latente del usuario\n",
    "        v_vec = V[j]  # vector latente del ítem\n",
    "\n",
    "        x_input = np.concatenate([u_vec, v_vec])  # entrada al modelo\n",
    "        rating = R_sparse[i, j]\n",
    "\n",
    "        X.append(x_input)\n",
    "        y.append(rating)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento XGBoost...\n",
      "RMSE en test: 1.0430\n"
     ]
    }
   ],
   "source": [
    "# Crear datos\n",
    "X, y = build_dataset_for_xgboost(R_sparse, U, V)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=200)\n",
    "print(\"Iniciando entrenamiento XGBoost...\")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE en test: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(uid, iid, U, V, xgb_model, user_to_index, item_to_index, mu):\n",
    "    # Verifica si el usuario y el ítem existen en los índices\n",
    "    if uid in user_to_index and iid in item_to_index:\n",
    "        user_idx = user_to_index[uid]\n",
    "        item_idx = item_to_index[iid]\n",
    "\n",
    "        # Construimos el vector de entrada para XGBoost\n",
    "        u_vec = U[user_idx]\n",
    "        v_vec = V[item_idx]\n",
    "        x_input = np.concatenate([u_vec, v_vec]).reshape(1, -1)\n",
    "\n",
    "        # Predicción con XGBoost\n",
    "        pred = xgb_model.predict(x_input)[0]\n",
    "    else:\n",
    "        # Si no se puede predecir, devolver la media global\n",
    "        pred = mu\n",
    "\n",
    "    # Clamping entre 1 y 10 con formato decimal \".0\"\n",
    "    return f\"{round(max(1, min(10, pred)))}.0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generacion csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando predicciones finales...\n",
      "Archivo 'predictions_pmf_xgboost.csv' generado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Celda 10: Generación del Archivo de Predicciones\n",
    "print(\"Generando predicciones finales...\")\n",
    "predictions = []\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    uid, iid, row_id = row['user'], row['item'], row['ID']\n",
    "    pred_rating = predict_rating(uid=uid, iid=iid, \n",
    "                   U=U, V=V, \n",
    "                   xgb_model=xgb_model, \n",
    "                   user_to_index=user_to_index, \n",
    "                   item_to_index=item_to_index, \n",
    "                   mu=mu)\n",
    "\n",
    "    predictions.append((row_id, pred_rating))\n",
    "\n",
    "# Crear el DataFrame con las predicciones\n",
    "predictions_df = pd.DataFrame(predictions, columns=[\"ID\", \"rating\"])\n",
    "\n",
    "# Guardar las predicciones en formato CSV\n",
    "output_filename = \"predictions_pmf_xgboost.csv\"\n",
    "predictions_df.to_csv(output_filename, index=False)\n",
    "print(f\"Archivo '{output_filename}' generado correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
