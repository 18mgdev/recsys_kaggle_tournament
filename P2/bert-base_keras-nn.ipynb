{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e5d10e2",
      "metadata": {
        "id": "2e5d10e2"
      },
      "outputs": [],
      "source": [
        "DATASETS_DIR = \"C:/Users/mgonz/Desktop/yelp/\"\n",
        "# DATASETS_DIR = \"./\"\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dde1c8ad",
      "metadata": {
        "id": "dde1c8ad"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(DATASETS_DIR + \"train_reviews.csv\")\n",
        "df_test = pd.read_csv(DATASETS_DIR + \"test_reviews.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d7ec95",
      "metadata": {
        "id": "82d7ec95"
      },
      "source": [
        "### df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6cf9fd0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "6cf9fd0b",
        "outputId": "8aee7fcc-d30a-4df8-fa04-974e67ac7a22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set shape: (967784, 9)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ZZO43qKB-s65zplC8RfJqw</td>\n",
              "      <td>-1BSu2dt_rOAqllw9ZDXtA</td>\n",
              "      <td>smkZq4G1AOm4V6p3id5sww</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Fantastic fresh food. The greek salad is amazi...</td>\n",
              "      <td>2016-09-30 15:49:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vojXOF_VOgvuKD95gCO8_Q</td>\n",
              "      <td>xpe178ng_gj5X6HgqtOing</td>\n",
              "      <td>96_c_7twb7hYRZ9HHrq01g</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Been a patient at Largo Med/Diagnostic Clinic ...</td>\n",
              "      <td>2020-12-09 14:39:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KwxdbiseRlIRNzpgvyjY0Q</td>\n",
              "      <td>axbaerf2Fk92OB4b9_peVA</td>\n",
              "      <td>e0AYjKfSF0DL-5C1CpOq6Q</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The location is convenient to my campus so I d...</td>\n",
              "      <td>2013-09-04 16:19:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3mwoBcTy-2gMh0L91uaIeA</td>\n",
              "      <td>_GOiybb0rImYKJfwyxEaGg</td>\n",
              "      <td>vF-uptiQ34pVLHJKzPHUlA</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I agree with all the other compliments posted ...</td>\n",
              "      <td>2019-03-02 12:24:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XfWf7XsBWs3kYyYq7Ns1ZQ</td>\n",
              "      <td>ojWKg3B5pH3ncAsxun3kUw</td>\n",
              "      <td>X28XK71RuEXPapeyUOwNzg</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>Wanting to help out the local economy, I thoug...</td>\n",
              "      <td>2020-04-23 18:26:29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id                 user_id             business_id  \\\n",
              "0  ZZO43qKB-s65zplC8RfJqw  -1BSu2dt_rOAqllw9ZDXtA  smkZq4G1AOm4V6p3id5sww   \n",
              "1  vojXOF_VOgvuKD95gCO8_Q  xpe178ng_gj5X6HgqtOing  96_c_7twb7hYRZ9HHrq01g   \n",
              "2  KwxdbiseRlIRNzpgvyjY0Q  axbaerf2Fk92OB4b9_peVA  e0AYjKfSF0DL-5C1CpOq6Q   \n",
              "3  3mwoBcTy-2gMh0L91uaIeA  _GOiybb0rImYKJfwyxEaGg  vF-uptiQ34pVLHJKzPHUlA   \n",
              "4  XfWf7XsBWs3kYyYq7Ns1ZQ  ojWKg3B5pH3ncAsxun3kUw  X28XK71RuEXPapeyUOwNzg   \n",
              "\n",
              "   stars  useful  funny  cool  \\\n",
              "0    5.0       0      0     0   \n",
              "1    1.0       2      0     1   \n",
              "2    4.0       0      0     0   \n",
              "3    5.0       0      0     0   \n",
              "4    5.0      10      4     7   \n",
              "\n",
              "                                                text                 date  \n",
              "0  Fantastic fresh food. The greek salad is amazi...  2016-09-30 15:49:32  \n",
              "1  Been a patient at Largo Med/Diagnostic Clinic ...  2020-12-09 14:39:51  \n",
              "2  The location is convenient to my campus so I d...  2013-09-04 16:19:51  \n",
              "3  I agree with all the other compliments posted ...  2019-03-02 12:24:14  \n",
              "4  Wanting to help out the local economy, I thoug...  2020-04-23 18:26:29  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Train set shape:\", df_train.shape)\n",
        "df_train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "af067e82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af067e82",
        "outputId": "647690a6-cb62-4c34-9e5b-958e5cf17a29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5., 1., 4., 2., 3.])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train[\"stars\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba4bf3aa",
      "metadata": {
        "id": "ba4bf3aa"
      },
      "source": [
        "### df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "61504790",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "61504790",
        "outputId": "e75e0595-3096-42a4-9cf4-ab3a23e98b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set shape: (414765, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ieYPmCImINjPzTDFmEKBKA</td>\n",
              "      <td>79F9QrQSet-b1yRCIM243Q</td>\n",
              "      <td>sXSUzImYOcRRI3xtG2M85g</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Amazing coffee and chill atmosphere. The staff...</td>\n",
              "      <td>2018-01-29 04:33:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>QIkJ8fZ4yx_QaHahWWszAA</td>\n",
              "      <td>chuM6TBkFHtTwJ6z96Hj1A</td>\n",
              "      <td>Ipt9ga67vVC_2ob3YmVwNA</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>I pass by this joint every time I make a run t...</td>\n",
              "      <td>2011-01-10 03:10:49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>seR2KhblYMWg-k9zzN6aYA</td>\n",
              "      <td>hF68a0mpu97u0oaryFYhyg</td>\n",
              "      <td>_RG4IByyBR528CMc7DefJA</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Came here when my kitten got very sick by the ...</td>\n",
              "      <td>2015-09-06 15:29:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BToo00Fi5pfJFA5MI2HM5g</td>\n",
              "      <td>G4yX5Q1tFfwSucFOmiyjdA</td>\n",
              "      <td>xxlbRiWWQkk-6LST3Hd12g</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>So I'll preface by saying we did have an overa...</td>\n",
              "      <td>2015-09-14 00:49:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FHJAzi1imodBit3RWK7zQA</td>\n",
              "      <td>Srqi1xb7exdB9uRHxDeEkw</td>\n",
              "      <td>LgGqdFLD7-ca0Z9F_q4Fuw</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>This place is a joke. Worst bar service ever. ...</td>\n",
              "      <td>2015-07-24 01:03:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id                 user_id             business_id  \\\n",
              "0  ieYPmCImINjPzTDFmEKBKA  79F9QrQSet-b1yRCIM243Q  sXSUzImYOcRRI3xtG2M85g   \n",
              "1  QIkJ8fZ4yx_QaHahWWszAA  chuM6TBkFHtTwJ6z96Hj1A  Ipt9ga67vVC_2ob3YmVwNA   \n",
              "2  seR2KhblYMWg-k9zzN6aYA  hF68a0mpu97u0oaryFYhyg  _RG4IByyBR528CMc7DefJA   \n",
              "3  BToo00Fi5pfJFA5MI2HM5g  G4yX5Q1tFfwSucFOmiyjdA  xxlbRiWWQkk-6LST3Hd12g   \n",
              "4  FHJAzi1imodBit3RWK7zQA  Srqi1xb7exdB9uRHxDeEkw  LgGqdFLD7-ca0Z9F_q4Fuw   \n",
              "\n",
              "   useful  funny  cool                                               text  \\\n",
              "0       1      0     1  Amazing coffee and chill atmosphere. The staff...   \n",
              "1       4      0     2  I pass by this joint every time I make a run t...   \n",
              "2       2      0     0  Came here when my kitten got very sick by the ...   \n",
              "3       2      0     0  So I'll preface by saying we did have an overa...   \n",
              "4       0      0     0  This place is a joke. Worst bar service ever. ...   \n",
              "\n",
              "                  date  \n",
              "0  2018-01-29 04:33:28  \n",
              "1  2011-01-10 03:10:49  \n",
              "2  2015-09-06 15:29:02  \n",
              "3  2015-09-14 00:49:17  \n",
              "4  2015-07-24 01:03:40  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Test set shape:\", df_test.shape)\n",
        "df_test.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a398aac3",
      "metadata": {
        "id": "a398aac3"
      },
      "source": [
        "### Creamos dataset de train y test del DF_TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e0e8681c",
      "metadata": {
        "id": "e0e8681c"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(df_train[\"text\"], df_train[\"stars\"], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "mIWCMqrEmaTY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIWCMqrEmaTY",
        "outputId": "4f1626fb-f603-491b-9553-a7be5c2799c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (774227,)\n",
            "X_val shape: (193557,)\n",
            "y_train shape: (774227,)\n",
            "y_val shape: (193557,)\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_val shape:\", y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "Z4ynZjILnAoP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "Z4ynZjILnAoP",
        "outputId": "4004ec47-6d39-4f23-d18e-6527c6c4bd19"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>300516</th>\n",
              "      <td>Love this place. Both times I came here, the c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695208</th>\n",
              "      <td>Costa Vista  is outstanding and flavorful food...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921436</th>\n",
              "      <td>I'm a big fan. A friend showed me a pic of his...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397552</th>\n",
              "      <td>Great team of PTs, the staff is friendly and k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953340</th>\n",
              "      <td>Do not sleep on them. If you are looking for a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "300516    Love this place. Both times I came here, the c...\n",
              "695208    Costa Vista  is outstanding and flavorful food...\n",
              "921436    I'm a big fan. A friend showed me a pic of his...\n",
              "397552    Great team of PTs, the staff is friendly and k...\n",
              "953340    Do not sleep on them. If you are looking for a...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W6GoSBwMJ6f4",
      "metadata": {
        "id": "W6GoSBwMJ6f4"
      },
      "source": [
        "### Pasamos los textos a embeddings BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "UHwzdG8LJ-pE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHwzdG8LJ-pE",
        "outputId": "76447d1b-9738-4d6a-867e-8587c9330593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "x_train\n",
            "x_val\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Carga del modelo y tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model_encoder = AutoModel.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model_encoder.to(device)\n",
        "model_encoder.eval()  # desactiva dropout\n",
        "\n",
        "# Función de mean pooling\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output.last_hidden_state  # (batch, seq_len, hidden)\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / input_mask_expanded.sum(1)\n",
        "\n",
        "# Función para procesar textos en batches\n",
        "def encode_texts(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}  # Mover a GPU/CPU\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model_encoder(**inputs)\n",
        "            embeddings = mean_pooling(outputs, inputs['attention_mask'])\n",
        "\n",
        "        all_embeddings.append(embeddings.cpu())  # Guardar siempre en CPU\n",
        "    return torch.cat(all_embeddings)\n",
        "\n",
        "# Aplicar a tus datos\n",
        "print(\"x_train\")\n",
        "X_train = encode_texts(X_train.tolist())\n",
        "print(\"x_val\")\n",
        "X_val = encode_texts(X_val.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2SFMhAg8dLL3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SFMhAg8dLL3",
        "outputId": "61b80915-0fb9-4725-93bb-d6f86d9f529b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💾 Guardando train en 'X_train.npy'\n",
            "💾 Guardando val en 'X_val.npy'\n"
          ]
        }
      ],
      "source": [
        "print(\"💾 Guardando train en 'X_train.npy'\")\n",
        "np.save(\"X_train.npy\", X_train)\n",
        "np.save(\"y_train.npy\", np.array(y_train))  # Guarda etiquetas alineadas\n",
        "\n",
        "print(\"💾 Guardando val en 'X_val.npy'\")\n",
        "np.save(\"X_val.npy\", X_val)\n",
        "np.save(\"y_val.npy\", np.array(y_val))  # Guarda etiquetas alineadas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gkHlCTKo_NPf",
      "metadata": {
        "id": "gkHlCTKo_NPf"
      },
      "source": [
        "### Entrenamos una red neuronal en keras (15 epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2a8cbd78",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Todos los datasets fueron cargados correctamente.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Ruta al directorio donde están los .npy\n",
        "base_path = r\"C:\\Users\\mgonz\\Desktop\\BERT embeddings datsets\"\n",
        "\n",
        "# Cargar los datasets\n",
        "X_train = np.load(os.path.join(base_path, \"X_train.npy\"))\n",
        "y_train = np.load(os.path.join(base_path, \"y_train.npy\"))\n",
        "\n",
        "X_val = np.load(os.path.join(base_path, \"X_val.npy\"))\n",
        "y_val = np.load(os.path.join(base_path, \"y_val.npy\"))\n",
        "\n",
        "X_test = np.load(os.path.join(base_path, \"X_test.npy\"))\n",
        "\n",
        "print(\"✅ Todos los datasets fueron cargados correctamente.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fT_4keZUmBeI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "fT_4keZUmBeI",
        "outputId": "4dad105d-0a88-4f91-9816-a16d982f8cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_dim: 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mgonz\\anaconda3\\envs\\recsys\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 3ms/step - loss: 0.8539 - mae: 0.6884 - val_loss: 0.8332 - val_mae: 0.7512\n",
            "Epoch 2/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2ms/step - loss: 0.5668 - mae: 0.5466 - val_loss: 0.5219 - val_mae: 0.5317\n",
            "Epoch 3/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2ms/step - loss: 0.5307 - mae: 0.5201 - val_loss: 0.5132 - val_mae: 0.5211\n",
            "Epoch 4/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2ms/step - loss: 0.5134 - mae: 0.5062 - val_loss: 0.4974 - val_mae: 0.4900\n",
            "Epoch 5/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2ms/step - loss: 0.5057 - mae: 0.4988 - val_loss: 0.4990 - val_mae: 0.5188\n",
            "Epoch 6/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 0.4974 - mae: 0.4923 - val_loss: 0.4907 - val_mae: 0.4969\n",
            "Epoch 7/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2ms/step - loss: 0.4891 - mae: 0.4879 - val_loss: 0.4857 - val_mae: 0.4897\n",
            "Epoch 8/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2ms/step - loss: 0.4862 - mae: 0.4855 - val_loss: 0.4820 - val_mae: 0.4864\n",
            "Epoch 9/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 0.4837 - mae: 0.4837 - val_loss: 0.4788 - val_mae: 0.4835\n",
            "Epoch 10/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 0.4790 - mae: 0.4810 - val_loss: 0.4800 - val_mae: 0.4842\n",
            "Epoch 11/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 0.4752 - mae: 0.4787 - val_loss: 0.4799 - val_mae: 0.4761\n",
            "Epoch 12/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 0.4744 - mae: 0.4785 - val_loss: 0.4780 - val_mae: 0.4755\n",
            "Epoch 13/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 0.4713 - mae: 0.4765 - val_loss: 0.4780 - val_mae: 0.4887\n",
            "Epoch 14/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 0.4696 - mae: 0.4760 - val_loss: 0.4802 - val_mae: 0.4939\n",
            "Epoch 15/15\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 0.4634 - mae: 0.4736 - val_loss: 0.4716 - val_mae: 0.4692\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1adb65033e0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "input_dim = X_train.shape[1]\n",
        "print(\"input_dim:\", input_dim)\n",
        "\n",
        "# Definir el modelo\n",
        "model_tt = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(input_dim,)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')  # Regresión\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model_tt.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# Entrenar\n",
        "model_tt.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=15,\n",
        "    batch_size=32\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "W__JBRqXmCBJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W__JBRqXmCBJ",
        "outputId": "a0cb5c97-e09e-479d-81b8-363bd6d3f91f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m6049/6049\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 694us/step\n",
            "📊 Métricas de regresión:\n",
            " - RMSE: 0.4716\n",
            " - MAE: 0.4692\n",
            " - R²: 0.7844\n",
            " - Accuracy (puntuaciones redondeadas): 0.6505\n"
          ]
        }
      ],
      "source": [
        "# Predicción\n",
        "y_pred = model_tt.predict(X_val)\n",
        "\n",
        "# Métricas de regresión\n",
        "rmse = mean_squared_error(y_val, y_pred)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "print(\"📊 Métricas de regresión:\")\n",
        "print(f\" - RMSE: {rmse:.4f}\")\n",
        "print(f\" - MAE: {mae:.4f}\")\n",
        "print(f\" - R²: {r2:.4f}\")\n",
        "\n",
        "# Redondear predicciones antes de comparar\n",
        "y_pred_rounded = np.round(y_pred).astype(int).astype(float)\n",
        "acc = accuracy_score(y_val, y_pred_rounded)\n",
        "print(f\" - Accuracy (puntuaciones redondeadas): {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TUhECGhf_Zyh",
      "metadata": {
        "id": "TUhECGhf_Zyh"
      },
      "source": [
        "### Exportamos CSV con los resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FYi8Mv84mB-w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYi8Mv84mB-w",
        "outputId": "d8a11846-9f33-4090-d589-c87688b64404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12962/12962\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 644us/step\n",
            "✅ CSV generado con éxito.\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Extraer los textos y los IDs\n",
        "texts_test = df_test[\"text\"].tolist()\n",
        "review_ids = df_test[\"review_id\"].tolist()\n",
        "\n",
        "# Paso 2: Sacar embeddings (usando el mismo modelo que usaste para entrenamiento)\n",
        "# X_test_embeddings = encode_texts(texts_test)\n",
        "X_test_embeddings = X_test\n",
        "\n",
        "# Paso 3: Predecir puntuaciones con XGBoost\n",
        "y_pred_test = model_tt.predict(X_test_embeddings).flatten()  # Aseguramos que sea vector plano\n",
        "\n",
        "# Paso 4: Crear DataFrame con las predicciones\n",
        "df_predictions = pd.DataFrame({\n",
        "    \"review_id\": review_ids,\n",
        "    \"stars\": y_pred_test\n",
        "})\n",
        "\n",
        "# # Paso 5: Redondear si lo deseas (opcional)\n",
        "# df_predictions[\"stars\"] = df_predictions[\"stars\"].round(1)\n",
        "# Paso 5: Redondear a entero y forzar que termine en .0\n",
        "df_predictions[\"stars\"] = df_predictions[\"stars\"].round().astype(int).astype(float)\n",
        "\n",
        "\n",
        "# Paso 6: Exportar a CSV\n",
        "df_predictions.to_csv(\"predicciones_bert-base_keras-nn.csv\", index=False)\n",
        "\n",
        "print(\"✅ CSV generado con éxito.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7c4060f",
      "metadata": {},
      "source": [
        "### Entrenamos una red neuronal en keras (10 epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c62d7c7e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Todos los datasets fueron cargados correctamente.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Ruta al directorio donde están los .npy\n",
        "base_path = r\"C:\\Users\\mgonz\\Desktop\\BERT embeddings datsets\"\n",
        "\n",
        "# Cargar los datasets\n",
        "X_train = np.load(os.path.join(base_path, \"X_train.npy\"))\n",
        "y_train = np.load(os.path.join(base_path, \"y_train.npy\"))\n",
        "\n",
        "X_val = np.load(os.path.join(base_path, \"X_val.npy\"))\n",
        "y_val = np.load(os.path.join(base_path, \"y_val.npy\"))\n",
        "\n",
        "X_test = np.load(os.path.join(base_path, \"X_test.npy\"))\n",
        "\n",
        "print(\"✅ Todos los datasets fueron cargados correctamente.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57920a39",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_dim: 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mgonz\\anaconda3\\envs\\recsys\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2ms/step - loss: 0.8437 - mae: 0.6869 - val_loss: 0.6205 - val_mae: 0.6126\n",
            "Epoch 2/10\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2ms/step - loss: 0.5622 - mae: 0.5438 - val_loss: 0.5164 - val_mae: 0.5150\n",
            "Epoch 3/10\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2ms/step - loss: 0.5275 - mae: 0.5181 - val_loss: 0.5073 - val_mae: 0.5143\n",
            "Epoch 4/10\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2ms/step - loss: 0.5108 - mae: 0.5043 - val_loss: 0.4983 - val_mae: 0.5063\n",
            "Epoch 5/10\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2ms/step - loss: 0.5038 - mae: 0.4975 - val_loss: 0.4941 - val_mae: 0.5119\n",
            "Epoch 6/10\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2ms/step - loss: 0.4956 - mae: 0.4922 - val_loss: 0.4911 - val_mae: 0.5035\n",
            "Epoch 7/10\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2ms/step - loss: 0.4917 - mae: 0.4893 - val_loss: 0.4995 - val_mae: 0.4915\n",
            "Epoch 8/10\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2ms/step - loss: 0.4841 - mae: 0.4842 - val_loss: 0.4913 - val_mae: 0.5015\n",
            "Epoch 9/10\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2ms/step - loss: 0.4806 - mae: 0.4826 - val_loss: 0.4874 - val_mae: 0.4881\n",
            "Epoch 10/10\n",
            "\u001b[1m24195/24195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2ms/step - loss: 0.4778 - mae: 0.4808 - val_loss: 0.4820 - val_mae: 0.4786\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1ae698e8e30>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_dim = X_train.shape[1]\n",
        "print(\"input_dim:\", input_dim)\n",
        "\n",
        "# Definir el modelo\n",
        "model_tt = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(input_dim,)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')  # Regresión\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model_tt.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# Entrenar\n",
        "model_tt.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "77049ead",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m6049/6049\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 656us/step\n",
            "📊 Métricas de regresión:\n",
            " - RMSE: 0.4820\n",
            " - MAE: 0.4786\n",
            " - R²: 0.7797\n",
            " - Accuracy (puntuaciones redondeadas): 0.6456\n"
          ]
        }
      ],
      "source": [
        "# Predicción\n",
        "y_pred = model_tt.predict(X_val)\n",
        "\n",
        "# Métricas de regresión\n",
        "rmse = mean_squared_error(y_val, y_pred)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "print(\"📊 Métricas de regresión:\")\n",
        "print(f\" - RMSE: {rmse:.4f}\")\n",
        "print(f\" - MAE: {mae:.4f}\")\n",
        "print(f\" - R²: {r2:.4f}\")\n",
        "\n",
        "# Redondear predicciones antes de comparar\n",
        "y_pred_rounded = np.round(y_pred).astype(int).astype(float)\n",
        "acc = accuracy_score(y_val, y_pred_rounded)\n",
        "print(f\" - Accuracy (puntuaciones redondeadas): {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11eafd1f",
      "metadata": {},
      "source": [
        "### Exportamos CSV con los resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "878c87f9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12962/12962\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 662us/step\n",
            "✅ CSV generado con éxito.\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Extraer los textos y los IDs\n",
        "texts_test = df_test[\"text\"].tolist()\n",
        "review_ids = df_test[\"review_id\"].tolist()\n",
        "\n",
        "# Paso 2: Sacar embeddings (usando el mismo modelo que usaste para entrenamiento)\n",
        "# X_test_embeddings = encode_texts(texts_test)\n",
        "X_test_embeddings = X_test\n",
        "\n",
        "# Paso 3: Predecir puntuaciones con XGBoost\n",
        "y_pred_test = model_tt.predict(X_test_embeddings).flatten()  # Aseguramos que sea vector plano\n",
        "\n",
        "# Paso 4: Crear DataFrame con las predicciones\n",
        "df_predictions = pd.DataFrame({\n",
        "    \"review_id\": review_ids,\n",
        "    \"stars\": y_pred_test\n",
        "})\n",
        "\n",
        "# # Paso 5: Redondear si lo deseas (opcional)\n",
        "# df_predictions[\"stars\"] = df_predictions[\"stars\"].round(1)\n",
        "# Paso 5: Redondear a entero y forzar que termine en .0\n",
        "df_predictions[\"stars\"] = df_predictions[\"stars\"].round().astype(int).astype(float)\n",
        "\n",
        "\n",
        "# Paso 6: Exportar a CSV\n",
        "df_predictions.to_csv(\"predicciones_bert-base_keras-nn-10epochs.csv\", index=False)\n",
        "\n",
        "print(\"✅ CSV generado con éxito.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "82d7ec95",
        "ba4bf3aa",
        "a398aac3",
        "lVBtgx3d_HsT",
        "gkHlCTKo_NPf",
        "TUhECGhf_Zyh",
        "ZWvgChMFDjnM",
        "Oa7cI19JDjnN",
        "jCHVPCSZDjnN"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "recsys",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
